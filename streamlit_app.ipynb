{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mrm8488/shared_colab_notebooks/blob/master/Create_streamlit_app.ipynb","timestamp":1703312482123}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In the absence of dedicated GPU resources, and with limited access, especially relying on Google Colab's constrained GPU capabilities, I opted to deploy a Streamlit app for my fine-tuned Llama 2 model. To visualize the app within a Google Colab environment, the following steps were taken:\n","\n","\n","* Execute the command `!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com`\n","\n","* The output will display an IP address, such as `35.203.134.132`, along with a generated URL like `https://calm-singers-travel.loca.lt` .\n","\n","* Visit the provided URL, which redirects to a website. On this website, enter the displayed IP address, e.g., `35.203.134.132`, in the input box.\n","\n","* The Streamlit app will then initiate and run within the Google Colab environment, accessible through the provided URL."],"metadata":{"id":"MsjMvFkDYHpN"}},{"cell_type":"code","metadata":{"id":"RvlYkCQ9vFiy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de3a0216-bc62-4125-ab0a-3fa26e2619ff","executionInfo":{"status":"ok","timestamp":1703323767231,"user_tz":-330,"elapsed":37024,"user":{"displayName":"Guna","userId":"02408497162992061156"}}},"source":["!pip install -q streamlit langchain huggingface_hub transformers sentence_transformers accelerate bitsandbytes"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","metadata":{"id":"waCfwniZOow8"},"source":["## Create a streamlit app example\n"]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from langchain.llms import HuggingFacePipeline\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n","from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n","\n","# Load the model and tokenizer\n","model_id = \"Guna0pro/llama-2-7b-html\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","# Quantization configuration\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","# Load base model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0}\n",")\n","\n","# Create a text-generation pipeline\n","generation_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    max_length=100\n",")\n","\n","local_llm = HuggingFacePipeline(pipeline=generation_pipeline)\n","\n","# Create a prompt template\n","template = \"\"\"Generate HTML code for the following instructions:\n","\n","Instructions: {instructions}\n","\n","HTML Code:\n","\"\"\"\n","\n","prompt = PromptTemplate(template=template, input_variables=[\"instructions\"])\n","\n","# Create an LLMChain\n","llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n","\n","# Streamlit app\n","def main():\n","    st.title(\"HTML Code Generator with Streamlit\")\n","\n","    # Create a list to store the conversation history\n","    conversation_history = []\n","\n","    # Get user instructions\n","    user_instructions = st.text_area(\"Enter instructions for HTML code:\")\n","\n","    if st.button(\"Generate HTML Code\"):\n","        # Run the HTML code generation logic\n","        html_code = llm_chain.run(user_instructions)\n","\n","        # Display the generated HTML code\n","        st.subheader(\"Generated HTML Code:\")\n","        st.code(html_code, language=\"html\")\n","\n","        # Add the current instructions and generated HTML code to the conversation history\n","        conversation_history.append((user_instructions, html_code))\n","\n","    # Display the conversation history\n","    st.subheader(\"Conversation History\")\n","    for instructions, code in conversation_history:\n","        st.text(f\"Instructions: {instructions}\")\n","        st.text(f\"Generated HTML Code: {code}\")\n","        st.text(\"-\" * 30)\n","\n","    # Add a button to clear the conversation history\n","    if st.button(\"Clear History\"):\n","        conversation_history.clear()\n","        st.success(\"Conversation history cleared.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"meJ36PefNftd","outputId":"d448e731-2c87-407f-be03-c009e00cd83b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703323767232,"user_tz":-330,"elapsed":24,"user":{"displayName":"Guna","userId":"02408497162992061156"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"xZlEJkmSOoxC"},"source":["## Install localtunnel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5d770eb-cdbf-40c2-e681-825236bf8660","id":"ZAyqQCQVOoxC","executionInfo":{"status":"ok","timestamp":1703323769971,"user_tz":-330,"elapsed":2755,"user":{"displayName":"Guna","userId":"02408497162992061156"}}},"source":["!npm install localtunnel"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n","\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n","\u001b[0m\n","+ localtunnel@2.0.2\n","added 22 packages from 22 contributors and audited 22 packages in 1.668s\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n","  run `npm audit fix` to fix them, or `npm audit` for details\n","\u001b[K\u001b[?25h"]}]},{"cell_type":"markdown","source":["## Run streamlit in background"],"metadata":{"id":"kccYE2lkN20y"}},{"cell_type":"code","source":["!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"],"metadata":{"id":"Zv912rRAN0fs","outputId":"9b95bb4d-863c-49f1-ccef-eb7d639274b8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["35.203.134.132\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.218s\n","your url is: https://calm-singers-travel.loca.lt\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"v5KIrUeySYKk"},"execution_count":null,"outputs":[]}]}